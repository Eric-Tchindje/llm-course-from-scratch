{"cells":[{"cell_type":"markdown","metadata":{"id":"PrHW0Y-4xMpa"},"source":["## LLM form scratch coure by Sebastian rashka"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80,"status":"ok","timestamp":1759415455215,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"gKUSzSAPxePb","outputId":"d2b25643-0f51-4120-cf05-f1a67c58147f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/llm-courses\n"]}],"source":["%cd /content/drive/MyDrive/Github/llm-courses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1759409838271,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"-NUNxC2cx9uJ","outputId":"f8a2089f-e903-452e-95c8-dbb525a6fef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/llm-courses\n"]}],"source":["!pwd"]},{"cell_type":"markdown","metadata":{"id":"u8fxqFliLvEH"},"source":["### Get data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1759409838334,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"Q_T7vCLjxIj9","outputId":"79cfc4e2-be2a-4687-f1a5-d97aa90128c9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('the-verdict.txt', <http.client.HTTPMessage at 0x7901954eebd0>)"]},"metadata":{},"execution_count":41}],"source":["# Dowload the data to link : https://en.wikisource.org/wiki/The_Verdict\n","import urllib.request\n","\n","url = (\"https://raw.githubusercontent.com/rasbt/\"\n","\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n","\"the-verdict.txt\")\n","\n","file_path = \"the-verdict.txt\"\n","urllib.request.urlretrieve(url, file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1759409840080,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"uR8rbQ88z2KJ","outputId":"e6bd5153-8d74-4a5d-f58b-b9da1832bfa5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20479, 'I HAD alwa')"]},"metadata":{},"execution_count":42}],"source":["# load  download text file\n","with open(file_path, 'r', encoding='utf-8') as f:\n","  raw_text = f.read()\n","\n","len(raw_text), raw_text[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1759409840278,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"HzSNFsXQ1sFV","outputId":"0d9b18a9-604d-42a7-c24a-559fa33afd62"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', ',', '|', '?', 'hmm', '!', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"]}],"source":["# Tokenizer the text using regular expression\n","import re\n","text = \"Hello, |?  hmm ! world. This, is a test.\"\n","result = re.split(r'([,.}!-?]|\\s+)', text)\n","tokens = [x for x in result if x.strip()]\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1759409840306,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"HlJ3hrBg5vZe","outputId":"57ccf7f1-7f9a-4fc6-cea7-dd01c348d387"},"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear']\n"]}],"source":["preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s+)', raw_text)\n","preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","print(preprocessed[:90])"]},{"cell_type":"markdown","metadata":{"id":"9fcarZHPL0lH"},"source":["### Create vocabulary of words and tokens with ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75,"status":"ok","timestamp":1759409824983,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"p5NIgala4NMn","outputId":"4d430880-ebd8-4019-df3e-a987cd5a4315"},"outputs":[{"output_type":"stream","name":"stdout","text":["1130\n"]}],"source":["# Convert token into token ID\n","\n","# get vocabulary list  : all list of the words\n","all_words = sorted(set(preprocessed))\n","\n","# create  the vocabulry dictionnary\n","vocab = { token : id for id, token in enumerate(all_words)}\n","print(len(vocab))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fEst6MUi8BL-"},"outputs":[],"source":["class SimpleTokkenizerV1:\n","  def __init__(self, vocab):\n","    self.str_to_int = vocab\n","    self.int_to_str = {id : token for token, id in vocab.items()}\n","\n","  def encode(self, text):\n","    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s+)', text)\n","    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","    ids = [self.str_to_int[token] for token in preprocessed]\n","    print(ids)\n","    return ids\n","\n","  def decode(self, ids):\n","    text = \" \".join([self.int_to_str[id] for id in ids ])\n","    text = re.sub(r'\\s+([,.?!\"()\\'])', r'', text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fV8-5fna96ad"},"outputs":[],"source":["tokenizer = SimpleTokkenizerV1(vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1759409825063,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"7wjmR-4gDopX","outputId":"39c3d836-53bd-4535-b15a-5274aa031ea7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n","[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"]}],"source":["text = \"\"\"\"It's the last he painted, you know,\"\n","Mrs. Gisburn said with pardonable pride.\"\"\"\n","\n","ids = tokenizer.encode(text)\n","print(ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1759409825087,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"h45V0WQ71CdL","outputId":"4b0e39a0-0f14-4fa2-b722-b6d42100dc36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\" It s the last he painted you know Mrs Gisburn said with pardonable pride'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["tokenizer.decode(ids)"]},{"cell_type":"markdown","metadata":{"id":"rUJEP_nBGN7R"},"source":["#### Add special maker : unknow token and endoftext token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1759409825142,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"ErA6iwziGZH0","outputId":"17a72d0b-7531-479d-87e9-5c3fdf0d6389"},"outputs":[{"output_type":"stream","name":"stdout","text":["1135\n"]}],"source":["preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s+)', raw_text)\n","all_tokens = sorted(list(set(preprocessed)))\n","all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n","vocab = {token:integer for integer, token in enumerate(all_tokens)}\n","print(len(vocab.items()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyNI1XwvImA7"},"outputs":[],"source":["class SimpleTokkenizerV2:\n","  def __init__(self, vocab):\n","    self.str_to_int = vocab\n","    self.int_to_str = {id : token for token, id in vocab.items()}\n","\n","  def encode(self, text):\n","    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s+)', text)\n","    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","    preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n","    ids = [self.str_to_int[token] for token in preprocessed]\n","    return ids\n","\n","  def decode(self, ids):\n","    text = \" \".join([self.int_to_str[id] for id in ids ])\n","    # text = re.sub(r'\\s+([,.?!\"()\\'])', r'', text)\n","    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'', text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V2jVUisJLvO"},"outputs":[],"source":["tokenizer2 = SimpleTokkenizerV2(vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1759409825229,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"fDifL8o8JTny","outputId":"507b92e6-9729-46a0-8ad3-738571cdaaa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"]}],"source":["text1 = \"Hello, do you like tea?\"\n","text2 = \"In the sunlit terraces of the palace.\"\n","text = \" <|endoftext|> \".join((text1, text2))\n","print(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9EwEJmQJgHC"},"outputs":[],"source":["ids = tokenizer2.encode(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1759409825423,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"bpt-Q-Y-JlN2","outputId":"90abfcdf-854d-44ba-8457-c5453864d46d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|unk|> do you like tea <|endoftext|> In the sunlit terraces of the <|unk|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["tokenizer2.decode(ids)"]},{"cell_type":"markdown","metadata":{"id":"TYu9zyZeKKtr"},"source":["#### Byte paire encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1759409825474,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"6tpnoqAyLqQH","outputId":"e8b4bf86-56f8-4978-912d-54b2ae38f9ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["tiktoken version: 0.11.0\n"]}],"source":["from importlib.metadata import version\n","import tiktoken\n","print(\"tiktoken version:\", version(\"tiktoken\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4496,"status":"ok","timestamp":1759409829974,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"agust88PMdER","outputId":"d39b311a-29cf-4018-f6aa-9c9dd410f7aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"]}],"source":["# instanciate the BPE tokenizer from tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","text = (\n","\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n","\"of someunknownPlace.\"\n",")\n","integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n","print(integers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1759409830009,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"Q4izAbKkMxRR","outputId":"38bc04a8-5806-4d5d-dac7-6278787329ba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["tokenizer.decode(integers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117,"status":"ok","timestamp":1759409830018,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"sIT71ZeXT3DD","outputId":"d8b931fb-d0d5-47c9-8a77-ba01af19e4d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["5145 [40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]\n"]}],"source":["# Tokenizer the whole book story\n","with open(file_path, 'r', encoding='utf-8') as f:\n","  raw_text = f.read()\n","\n","#encode raw data\n","ids = tokenizer.encode(raw_text)\n","print(len(ids) , ids[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1759409830044,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"f_3XCeYaUkeN","outputId":"013a5a83-8f3e-44f7-9a61-d2e63f5322fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["x = [40, 367, 2885, 1464]\n","y = [367, 2885, 1464, 1807]\n"]}],"source":["#Ccontext size determin how may token are included into the input\n","context_size=4\n","x = ids[:context_size]\n","y = ids[1:context_size+1]\n","\n","print(f\"x = {x}\")\n","print(f\"y = {y}\" )"]},{"cell_type":"markdown","metadata":{"id":"nlUgtb5YXrMV"},"source":["#### Implement custom dataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojxh9T5FXyNy"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class GPTDatasetV1(Dataset):\n","  def __init__(self, text, tokenizer, max_length, stride):\n","    self.input_ids = []\n","    self.target_ids = []\n","\n","    self.tokens_ids = tokenizer.encode(text)\n","    assert len(self.tokens_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n","\n","\n","    for i in range(0, len(self.tokens_ids) - max_length, stride):\n","      input_chunk = self.tokens_ids[i:i + max_length ]\n","      target_chunk = self.tokens_ids[i + 1:i + max_length + 1]\n","      self.input_ids.append( torch.tensor(input_chunk))\n","      self.target_ids.append(torch.tensor(target_chunk))\n","\n","  def __len__(self):\n","    return len(self.input_ids)\n","\n","\n","  def __getitem__(self, idx):\n","    return self.input_ids[idx], self.target_ids[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ni6cpm0WcIkN"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Data loader function\n","def create_dataloader_v1(text, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True ):\n","  tokenizer = tiktoken.get_encoding(\"gpt2\")\n","  dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n","  dataloader = DataLoader(\n","      dataset,\n","      batch_size=batch_size,\n","      shuffle=shuffle,\n","      drop_last=drop_last\n","  )\n","\n","  return dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1759409835756,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"bMt5R59Xdcob","outputId":"a6580896-aad3-4a29-f783-54565750fb8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input :\n","tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","Target :\n"," tensor([[  367,  2885,  1464,  1807],\n","        [ 3619,   402,   271, 10899],\n","        [ 2138,   257,  7026, 15632],\n","        [  438,  2016,   257,   922],\n","        [ 5891,  1576,   438,   568],\n","        [  340,   373,   645,  1049],\n","        [ 5975,   284,   502,   284],\n","        [ 3285,   326,    11,   287]])\n"]}],"source":["# load  download text file\n","with open(file_path, 'r', encoding='utf-8') as f:\n","  raw_text = f.read()\n","\n","dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n","data_iter = iter(dataloader)\n","\n","input, target = next(data_iter)\n","print(f\"Input :\\n{input}\")\n","print(f\"Target :\\n {target}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1759409835921,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"aKR1HG-jlhex","outputId":"dd26aa00-7712-458b-ebb3-18c38abd3d3c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(50257, 256)"]},"metadata":{},"execution_count":28}],"source":["#create token embedding layer\n","vocab_size = 50257\n","output_dim = 256\n","token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n","token_embedding_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1759409836007,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"tBtNvPJ4nVEX","outputId":"4d8686bd-af36-4de3-de82-518c1eb5b704"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs:\n"," tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","\n","Inputs shape:\n"," torch.Size([8, 4])\n"]}],"source":["max_length = 4\n","dataloader = create_dataloader_v1(\n","  raw_text, batch_size=8, max_length=max_length,\n","  stride=max_length, shuffle=False\n",")\n","\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)\n","print(\"Token IDs:\\n\", inputs)\n","print(\"\\nInputs shape:\\n\", inputs.shape)"]},{"cell_type":"markdown","metadata":{"id":"1OWFuK5Eowpw"},"source":["#### use the embedding layer to embed these token IDs into 256-dimensional vectors:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1759409836050,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"uv6SOi99o3Tg","outputId":"669aeda6-4bac-4562-982b-15c4b64cd1d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n"]}],"source":["token_embeddings = token_embedding_layer(inputs)\n","print(token_embeddings.shape)"]},{"cell_type":"markdown","metadata":{"id":"0fX2TG6xB7Tq"},"source":["###Create positional embeding with the  same dim as token embeding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67,"status":"ok","timestamp":1759409836122,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"},"user_tz":-60},"id":"74H7-sdQCFaJ","outputId":"65e621fc-f6e5-47aa-d8b6-c4f6efa8035a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 256])\n"]}],"source":["context_length = max_length\n","pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n","pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n","print(pos_embeddings.shape)"]},{"cell_type":"markdown","source":["### Coding attentiion mechanism : simple way"],"metadata":{"id":"wyUPqbHVCuXw"}},{"cell_type":"code","source":["import torch\n","\n","inputs = torch.tensor(\n","  [[0.43, 0.15, 0.89], # Your\n","  [0.55, 0.87, 0.66], # journey\n","  [0.57, 0.85, 0.64], # starts\n","  [0.22, 0.58, 0.33], # with\n","  [0.77, 0.25, 0.10], # one\n","  [0.05, 0.80, 0.55]] # step\n",")\n"],"metadata":{"id":"0E8nblqeI6y5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compute attention score for token 2\n","query = inputs[1]\n","attn_scores_2 = torch.empty(inputs.shape[0])\n","for i, x_i in enumerate(inputs):\n","  attn_scores_2[i] = torch.dot(x_i, query)\n","\n","\n","print(attn_scores_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMmaNPw4JDm2","executionInfo":{"status":"ok","timestamp":1759409836359,"user_tz":-60,"elapsed":26,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"30fc7a8f-3fa1-431f-971f-9389f4cd112b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"]}]},{"cell_type":"code","source":["#normalize the attention score\n","\n","def softmax_naive(x):\n","  return torch.exp(x) / torch.exp(x).sum(dim=0)\n","\n","attn_weights_2_naive = softmax_naive(attn_scores_2)\n","print(\"Attention weights:\", attn_weights_2_naive)\n","print(\"Sum:\", attn_weights_2_naive.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KLhf0SIJWsV","executionInfo":{"status":"ok","timestamp":1759409836404,"user_tz":-60,"elapsed":37,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"1f54fbdf-3b08-40d4-9948-377e9b7ba2a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","Sum: tensor(1.)\n"]}]},{"cell_type":"code","source":["#using the torch softmax\n","attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n","print(\"Attention weights:\", attn_weights_2)\n","print(\"Sum:\", attn_weights_2.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wp8RenXwJsQ5","executionInfo":{"status":"ok","timestamp":1759409836427,"user_tz":-60,"elapsed":26,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"7c53bf42-4f1b-45e7-da99-6e917ab72a28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","Sum: tensor(1.)\n"]}]},{"cell_type":"markdown","source":["#### calculating the context vector z(2) by multiplying the embedded input tokens, x(i),  with the corresponding attention weights and then summing the resulting vectors.\n","\n","Thus, context vector z(2) is the weighted sum of all input\n","vectors, obtained by multiplying each input vector by its\n","corresponding attention weight"],"metadata":{"id":"JhvunWuHJ6iW"}},{"cell_type":"code","source":["query = inputs[1]\n","\n","context_vec_2 = torch.zeros(query.shape)\n","for i,x_i in enumerate(inputs):\n","  context_vec_2 += attn_weights_2[i]*x_i\n","\n","print(context_vec_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cCKR2LeKELa","executionInfo":{"status":"ok","timestamp":1759409836462,"user_tz":-60,"elapsed":29,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"25f45d46-a3f1-4242-abdf-67867419472b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.4419, 0.6515, 0.5683])\n"]}]},{"cell_type":"code","source":["#cmute the atten score\n","attn_scores = torch.matmul(inputs,  inputs.T)\n","print(attn_scores)\n","\n","#we normalize each row\n","attn_weights = torch.softmax(attn_scores, dim=1)\n","print(attn_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Co6y6m9rKPrn","executionInfo":{"status":"ok","timestamp":1759409836500,"user_tz":-60,"elapsed":33,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"9cb0fadf-5d88-41d7-f709-e8894b360450"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n","        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n","        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n","        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n","        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n","        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n","tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n","        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n","        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n","        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n","        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n","        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"]}]},{"cell_type":"code","source":["# compute all atttention vectors\n","all_context_vecs = torch.matmul(attn_weights, inputs)\n","print(all_context_vecs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhUsGp3lKqRz","executionInfo":{"status":"ok","timestamp":1759409836531,"user_tz":-60,"elapsed":34,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"306d8576-2952-415c-f1c5-6a1155c78090"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4421, 0.5931, 0.5790],\n","        [0.4419, 0.6515, 0.5683],\n","        [0.4431, 0.6496, 0.5671],\n","        [0.4304, 0.6298, 0.5510],\n","        [0.4671, 0.5910, 0.5266],\n","        [0.4177, 0.6503, 0.5645]])\n"]}]},{"cell_type":"markdown","source":["### Implement self attention with learning"],"metadata":{"id":"_n5f1Heq_Qjx"}},{"cell_type":"markdown","source":["\n","Define 3 variables :\n","* The second input element\n","* The input embedding size, d=3\n","* The output embedding size, d_out=2"],"metadata":{"id":"0BeWcV9NGkWt"}},{"cell_type":"code","source":["x_2  = inputs[1]\n","d_in = inputs.shape[1]\n","d_out = 2\n","\n","\n","x_2, d_in, d_out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NgxRQku_gr0","executionInfo":{"status":"ok","timestamp":1759409842567,"user_tz":-60,"elapsed":1779,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"f087fea8-3299-4e5f-8b6f-c66ee7aaf299"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.5500, 0.8700, 0.6600]), 3, 2)"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["####Next, we initialize the three weight matrices Wq, Wk, and Wv"],"metadata":{"id":"PdUL1cUSG1vy"}},{"cell_type":"code","source":["###we initialize the three weight matrices Wq, Wk, and Wv\n","torch.manual_seed(123)\n","W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n","W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n","W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"],"metadata":{"id":"AfgMl6IL_6K9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Compute the 3 matrix :  keys, queries and values  \n","\n","we successfully projected the six input tokens from a three-dimensional onto a two-\n","dimensional embedding space:"],"metadata":{"id":"8FlEs-BCG_Dy"}},{"cell_type":"code","source":["###obtain all keys and values via matrix multiplication\n","keys = inputs @ W_key\n","values = inputs @ W_value\n","queries = inputs @ W_query\n","print(\"keys.shape:\", keys.shape)\n","print(\"values.shape:\", values.shape)\n","print(\"queries shape\", queries.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-FAcY_IBKJk","executionInfo":{"status":"ok","timestamp":1759411359934,"user_tz":-60,"elapsed":61,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"ead6db1a-ae41-451f-c17d-970a16c5e3cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["keys.shape: torch.Size([6, 2])\n","values.shape: torch.Size([6, 2])\n","queries shape torch.Size([6, 2])\n"]}]},{"cell_type":"markdown","source":["####The attention score computation is a dot-product\n","computation similar to what we used in the simplified self-attention\n","mechanism in section 3.3. The new aspect here is that we are not\n","directly computing the dot-product between the input elements but\n","using the query and key obtained by transforming the inputs via the\n","respective weight matrices."],"metadata":{"id":"QMJMALhAGX1x"}},{"cell_type":"code","source":["##compute the attention score  ω22 for token 2 :\n","keys_2 = keys[1] # get key associate with token 2\n","query_2 = queries[1] #get query associate with token 2\n","\n","#compute attention score for token 2 embedding\n","attn_scores_22 = torch.dot(query_2, keys_2)\n","attn_scores_22"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtZodFwCB5uM","executionInfo":{"status":"ok","timestamp":1759411430843,"user_tz":-60,"elapsed":33,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"e192abfe-6e85-4ba7-f00a-3c827342ce20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.8524)"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["we can generalize this computation to all attention\n","scores via matrix multiplication"],"metadata":{"id":"XebssHcmH1Ch"}},{"cell_type":"code","source":["#compute attention score for  all tokens embedding\n","attn_scores_2 = query_2 @ keys.T\n","print(attn_scores_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0rlvQeCHWLa","executionInfo":{"status":"ok","timestamp":1759411945412,"user_tz":-60,"elapsed":38,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"66476345-77ab-4567-de81-cef63ce9af52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"]}]},{"cell_type":"markdown","source":["#### Compute attention *weight*\n","\n","we want to go from the attention scores to the\n","attention weights, as illustrated in figure 3.16. We compute\n","the attention weights by scaling the attention scores and\n","using the softmax function. However, now we scale the\n","attention scores by dividing them by the square root of the\n","embedding dimension of the keys (taking the square root is\n","mathematically the same as exponentiating by 0.5"],"metadata":{"id":"R6myPLOPIktt"}},{"cell_type":"code","source":["d_k = keys.shape[-1]\n","attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1) #softmax n\n","print(attn_weights_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6W47k47QIpfz","executionInfo":{"status":"ok","timestamp":1759412135252,"user_tz":-60,"elapsed":35,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"e5785b76-4952-434e-edd3-fcd033a64e59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"]}]},{"cell_type":"markdown","source":["\n","\n","#### Compute the context vector\n","\n","Now, the final step is to compute the context vectors,\n","* we compute the context vector by combining all value vectors via the\n","attention weights."],"metadata":{"id":"DJ6v1ru4I3M5"}},{"cell_type":"code","source":["#create value vector\n","context_vec_2 = attn_weights_2 @ values\n","print(context_vec_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcnvlGUNK4TQ","executionInfo":{"status":"ok","timestamp":1759413413909,"user_tz":-60,"elapsed":55,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"8d31fc7a-d8e6-43bc-a51b-b54234a8becc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.3061, 0.8210])\n"]}]},{"cell_type":"markdown","source":["So far, we’ve only computed a single context vector, z(2).\n","Next, we will generalize the code to compute all context\n","vectors in the input sequence, z(1) to z(T)."],"metadata":{"id":"6-FtTReBNjA0"}},{"cell_type":"markdown","source":["#### Implementing a compact self-attention Python class\n","\n","In this PyTorch code, SelfAttention_v1 is a class derived from\n","nn.Module, which is a fundamental building block of PyTorch\n","models that provides necessary functionalities for model\n","layer creation and management.\n","\n","The __init__ method initializes trainable weight matrices\n","(W_query, W_key, and W_value) for queries, keys, and values,\n","each transforming the input dimension d_in to an output\n","dimension d_out.\n","\n","During the forward pass, using the forward method, we\n","compute the attention scores (attn_scores) by multiplying\n","queries and keys, normalizing these scores using softmax.\n","Finally, we create a context vector by weighting the values\n","with these normalized attention scores."],"metadata":{"id":"Uz8FK4WFOApW"}},{"cell_type":"code","source":["!!"],"metadata":{"id":"9Kn-P9mpT5A1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class SelfAttention_v1(torch.nn.Module):\n","  def __init__(self, d_in, d_out):\n","    super().__init__()\n","    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n","    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n","    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n","\n","\n","  def forward(self, inputs):\n","    queries = inputs @ self.W_query\n","    keys = inputs @ self.W_key\n","    values = inputs @ self.W_value\n","\n","    attn_scores = queries @ keys.T\n","    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","    context_vecs = attn_weights @ values\n","\n","    return context_vecs"],"metadata":{"id":"bfXkmqgiRNQq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since inputs contains six embedding vectors, this results in a\n","matrix storing the six context vectors"],"metadata":{"id":"9fgGOo1gS7HG"}},{"cell_type":"code","source":["torch.manual_seed(123)\n","sa_v1 = SelfAttention_v1(d_in, d_out)\n","print(sa_v1(inputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13qXYsrLSpdW","executionInfo":{"status":"ok","timestamp":1759414766646,"user_tz":-60,"elapsed":94,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"40755281-b80a-41b1-c2bf-052ffbaed8da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2996, 0.8053],\n","        [0.3061, 0.8210],\n","        [0.3058, 0.8203],\n","        [0.2948, 0.7939],\n","        [0.2927, 0.7891],\n","        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"tchindjeeric2@gmail.com\"\n","!git config --global user.name \"Tchindje\"\n","!git config --global init.defaultBranch master"],"metadata":{"id":"sTbQEJJrVuFC","executionInfo":{"status":"ok","timestamp":1759416890879,"user_tz":-60,"elapsed":380,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["!git init"],"metadata":{"id":"mbpURv6IVvN5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759416893739,"user_tz":-60,"elapsed":443,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"78e82b33-9621-472d-c6f3-adadeb5fb0f0"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized empty Git repository in /content/drive/MyDrive/Github/llm-courses/.git/\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"VeuWiyYMZhk7","executionInfo":{"status":"ok","timestamp":1759416883536,"user_tz":-60,"elapsed":219,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vetM26i3ZsJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"init commit\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jULaAipYV94I","executionInfo":{"status":"ok","timestamp":1759416448105,"user_tz":-60,"elapsed":1296,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"ebc9ad59-c36a-4815-b6b5-e364559703e6"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["[master ec00907] init commit\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"]}]},{"cell_type":"code","source":["!git remote remove origin"],"metadata":{"id":"71dN7cbCYwya","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759416439255,"user_tz":-60,"elapsed":234,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"191471ed-3e1d-45f5-b13a-fc8143657cb7"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["error: No such remote: 'origin'\n"]}]},{"cell_type":"code","source":["# !git remote add origin https://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@github.com/Eric-Tchindje/llm-course-from-scratch.git\n","###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"],"metadata":{"id":"osRP4Ow4WIGU","executionInfo":{"status":"ok","timestamp":1759416452286,"user_tz":-60,"elapsed":130,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["!git remote -v"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSd2vEqxZJyF","executionInfo":{"status":"ok","timestamp":1759416466625,"user_tz":-60,"elapsed":173,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"0c7ddf4a-4923-4707-840a-038f4b5c6829"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["origin\thttps://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@github.com/Eric-Tchindje/llm-course-from-scratch.git (fetch)\n","origin\thttps://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@github.com/Eric-Tchindje/llm-course-from-scratch.git (push)\n"]}]},{"cell_type":"code","source":["# !git rm --cached \"LLm-course_chap2_working _on_text.ipynb\"\n","!git commit -m \"Remove accidentally committed token\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsC9PUqVaXqw","executionInfo":{"status":"ok","timestamp":1759416806775,"user_tz":-60,"elapsed":704,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"3d75c966-7de1-45d6-9607-e928160ea46c"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["[master b71f6f9] Remove accidentally committed token\n"," 1 file changed, 1 deletion(-)\n"," delete mode 100644 LLm-course_chap2_working _on_text.ipynb\n"]}]},{"cell_type":"code","source":["!git push -u origin master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyoWkSr8Wejt","executionInfo":{"status":"ok","timestamp":1759416824663,"user_tz":-60,"elapsed":1482,"user":{"displayName":"Éric Tchindje","userId":"06793528037541974450"}},"outputId":"e11cb01e-0feb-4fd5-e98d-4f3ac15f8cde"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 9, done.\n","Counting objects:  11% (1/9)\rCounting objects:  22% (2/9)\rCounting objects:  33% (3/9)\rCounting objects:  44% (4/9)\rCounting objects:  55% (5/9)\rCounting objects:  66% (6/9)\rCounting objects:  77% (7/9)\rCounting objects:  88% (8/9)\rCounting objects: 100% (9/9)\rCounting objects: 100% (9/9), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  12% (1/8)\rCompressing objects:  25% (2/8)\rCompressing objects:  37% (3/8)\rCompressing objects:  50% (4/8)\rCompressing objects:  62% (5/8)\rCompressing objects:  75% (6/8)\rCompressing objects:  87% (7/8)\rCompressing objects: 100% (8/8)\rCompressing objects: 100% (8/8), done.\n","Writing objects:  11% (1/9)\rWriting objects:  22% (2/9)\rWriting objects:  33% (3/9)\rWriting objects:  44% (4/9)\rWriting objects:  55% (5/9)\rWriting objects:  66% (6/9)\rWriting objects:  77% (7/9)\rWriting objects:  88% (8/9)\rWriting objects: 100% (9/9)\rWriting objects: 100% (9/9), 19.06 KiB | 542.00 KiB/s, done.\n","Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), done.\u001b[K\n","remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/master.\u001b[K\n","remote: \n","remote: - GITHUB PUSH PROTECTION\u001b[K\n","remote:   —————————————————————————————————————————\u001b[K\n","remote:     Resolve the following violations before pushing again\u001b[K\n","remote: \n","remote:     - Push cannot contain secrets\u001b[K\n","remote: \n","remote:     \u001b[K\n","remote:      (?) Learn how to resolve a blocked push\u001b[K\n","remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n","remote:     \u001b[K\n","remote:     \u001b[K\n","remote:       —— GitHub Personal Access Token ——————————————————————\u001b[K\n","remote:        locations:\u001b[K\n","remote:          - commit: ec00907f93e499a555cc3b2cde95d56e22236036\u001b[K\n","remote:            path: LLm-course_chap2_working _on_text.ipynb:1\u001b[K\n","remote:          - commit: ec00907f93e499a555cc3b2cde95d56e22236036\u001b[K\n","remote:            path: LLm-course_chap2_working _on_text.ipynb:1\u001b[K\n","remote:     \u001b[K\n","remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n","remote:        https://github.com/Eric-Tchindje/llm-course-from-scratch/security/secret-scanning/unblock-secret/33VyKvmEHscGLdHBE0PBQqnWjWw\u001b[K\n","remote:     \u001b[K\n","remote:     \u001b[K\n","remote:       —— GitHub Personal Access Token ——————————————————————\u001b[K\n","remote:        locations:\u001b[K\n","remote:          - commit: ec00907f93e499a555cc3b2cde95d56e22236036\u001b[K\n","remote:            path: LLm-course_chap2_working _on_text.ipynb:1\u001b[K\n","remote:     \u001b[K\n","remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n","remote:        https://github.com/Eric-Tchindje/llm-course-from-scratch/security/secret-scanning/unblock-secret/33VyKvn4TSSkwPWv2x4K4675XIK\u001b[K\n","remote:     \u001b[K\n","remote: \n","remote: \n","To https://github.com/Eric-Tchindje/llm-course-from-scratch.git\n"," \u001b[31m! [remote rejected]\u001b[m master -> master (push declined due to repository rule violations)\n","\u001b[31merror: failed to push some refs to 'https://github.com/Eric-Tchindje/llm-course-from-scratch.git'\n","\u001b[m"]}]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"mount_file_id":"1fG9Og5_Um3tD95VFf05Cbyd3J-kh3qcP","authorship_tag":"ABX9TyPP6WmuxTYrCfXjn7XujHdc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}